{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general purpose packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#data processing\n",
    "import re, string\n",
    "import emoji\n",
    "import nltk\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#transformers\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertModel\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import TFRobertaModel\n",
    "\n",
    "#keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#set seed for reproducibility\n",
    "seed=42\n",
    "\n",
    "# #set style for plots\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.despine()\n",
    "# plt.style.use(\"seaborn-whitegrid\")\n",
    "# plt.rc(\"figure\", autolayout=True)\n",
    "# plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Corona_NLP_train.csv',encoding='ISO-8859-1')\n",
    "df_test = pd.read_csv('Corona_NLP_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   UserName       41157 non-null  int64 \n",
      " 1   ScreenName     41157 non-null  int64 \n",
      " 2   Location       32567 non-null  object\n",
      " 3   TweetAt        41157 non-null  object\n",
      " 4   OriginalTweet  41157 non-null  object\n",
      " 5   Sentiment      41157 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9824\\1259316306.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['TweetAt'] = pd.to_datetime(df['TweetAt'])\n"
     ]
    }
   ],
   "source": [
    "df['TweetAt'] = pd.to_datetime(df['TweetAt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='OriginalTweet',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41157 entries, 0 to 41156\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   UserName       41157 non-null  int64         \n",
      " 1   ScreenName     41157 non-null  int64         \n",
      " 2   Location       32567 non-null  object        \n",
      " 3   TweetAt        41157 non-null  datetime64[ns]\n",
      " 4   OriginalTweet  41157 non-null  object        \n",
      " 5   Sentiment      41157 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep CLean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
    "\n",
    "#Clean emojis from text\n",
    "import re\n",
    "\n",
    "def strip_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001f926-\\U0001f937\"\n",
    "                           u\"\\U00010000-\\U0010ffff\"\n",
    "                           u\"\\u2640-\\u2642\"\n",
    "                           u\"\\u2600-\\u2B55\"\n",
    "                           u\"\\u200d\"\n",
    "                           u\"\\u23cf\"\n",
    "                           u\"\\u23e9\"\n",
    "                           u\"\\u231a\"\n",
    "                           u\"\\ufe0f\"  # dingbats\n",
    "                           u\"\\u3030\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_new = []\n",
    "for t in df.OriginalTweet:\n",
    "    texts_new.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_new_test = []\n",
    "for t in df_test.OriginalTweet:\n",
    "    texts_new_test.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = texts_new\n",
    "df_test['text_clean'] = texts_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              and and\n",
       "1    advice talk to your neighbours family to excha...\n",
       "2    coronavirus australia woolworths to give elder...\n",
       "3    my food stock is not the only one which is emp...\n",
       "4    me ready to go at supermarket during the covid...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    trending new yorkers encounter empty supermark...\n",
       "1    when i couldnt find hand sanitizer at fred mey...\n",
       "2    find out how you can protect yourself and love...\n",
       "3    panic buying hits newyork city as anxious shop...\n",
       "4    toiletpaper dunnypaper coronavirus coronavirus...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order',\n",
       "       'coronavirus australia woolworths to give elderly disabled dedicated shopping hours amid covid19 outbreak',\n",
       "       'my food stock is not the only one which is empty please dont panic there will be enough food for everyone if you do not take more than you need stay calm stay safe covid19france covid19 covid19 coronavirus confinement confinementotal confinementgeneral',\n",
       "       'me ready to go at supermarket during the covid19 outbreak not because im paranoid but because my food stock is litteraly empty the coronavirus is a serious thing but please dont panic it causes shortage coronavirusfrance restezchezvous stayathome confinement',\n",
       "       'as news of the regions first confirmed covid19 case came out of sullivan county last week people flocked to area stores to purchase cleaning supplies hand sanitizer food toilet paper and other goods reports',\n",
       "       'cashier at grocery store was sharing his insights on covid19 to prove his credibility he commented im in civics class so i know what im talking about',\n",
       "       'was at the supermarket today didnt buy toilet paper rebel toiletpapercrisis covid19'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clean'][1:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = []\n",
    "for text in df.text_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    text_len.append(tweet_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_len'] = text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len_test = []\n",
    "for text in df_test.text_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    text_len_test.append(tweet_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text_len'] = text_len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DF SHAPE: (41157, 4)\n",
      " DF TEST SHAPE: (3798, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\" DF SHAPE: {df.shape}\")\n",
    "print(f\" DF TEST SHAPE: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text_len'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['text_len'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DF SHAPE: (40935, 4)\n",
      " DF TEST SHAPE: (3792, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\" DF SHAPE: {df.shape}\")\n",
    "print(f\" DF TEST SHAPE: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data deeper cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df['text_clean'].values:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "max_len=np.max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX TOKENIZED SENTENCE LENGTH: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 1622, TEXT: zsah policie proti spekulantm s roukami na mj popud hejtman steckho kraje ve spoluprci s podle krizovho zkona zajistil tm 700 tisrouek od firmy kter je mla dodat na zdravotnkm ale na posledn chvli se snaila navyovat cenu spolutozvladneme\n",
      "INDEX: 13623, TEXT: hoy aplaudo a mi segunda familia aplaudoanuestrosheroes aquellos con los que he compartido tantas noches de trabajo y tanta alegra s que como siempre dan todo por el bien de su comunidad presidente por ellos tambin cuarentenanacionalya cuidemosalosquecuidan\n",
      "INDEX: 16548, TEXT: bir mddettir spermarketlerin lojistik hizmeti avusturya ordusu desteiyle yaplyor dn corona tedavisi iin 22 milyon luk bir aratrma gelitirme btesi aklad hkmet geen hafta da 35 milyon luk 2 yardm paketi aklanmt viyanadan haberler bu kadar\n",
      "INDEX: 36953, TEXT: 11 nisan cumartesi itibariyle bbnin tm hizmetleri sokaa kma serbestisi olanlar iin devam edecek halk ekmek ve hamidiye su 100 retime geti bb tm stanbulun gda ihtiyacna yetecek kapasitededir halkmz sakin olsun ve gvende hissetsin ltfen herkes evine dnsn\n"
     ]
    }
   ],
   "source": [
    "token_lens = []\n",
    "\n",
    "for i,txt in enumerate(df['text_clean'].values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    if len(tokens)>80:\n",
    "        print(f\"INDEX: {i}, TEXT: {txt}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_lens'] = token_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>token_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>ZÃ¡sah policie proti spekulant?m s rouÂkami. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>zsah policie proti spekulantm s roukami na mj ...</td>\n",
       "      <td>39</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37156</th>\n",
       "      <td>11 Nisan Cumartesi itibariyle ?BBÂnin tÃ¼m hi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>11 nisan cumartesi itibariyle bbnin tm hizmetl...</td>\n",
       "      <td>39</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16632</th>\n",
       "      <td>Bir mÃ¼ddettir sÃ¼permarketlerin lojistik hizm...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bir mddettir spermarketlerin lojistik hizmeti ...</td>\n",
       "      <td>36</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>Hoy aplaudo a mi segunda familia #AplaudoANues...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>hoy aplaudo a mi segunda familia aplaudoanuest...</td>\n",
       "      <td>38</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>Supermercados Econo confirman que un empleado ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>supermercados econo confirman que un empleado ...</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14593</th>\n",
       "      <td>Na, wer war denn da am Werk? Gestern Nachmitta...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>na wer war denn da am werk gestern nachmittag ...</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899</th>\n",
       "      <td>Kindly contact Us bamy global merchandise for ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>kindly contact us bamy global merchandise for ...</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>Keine WertgegenstÃ¤nde im Fahrzeug lassen! - D...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>keine wertgegenstnde im fahrzeug lassen diesen...</td>\n",
       "      <td>33</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>Impct of #coronavirus i hve sen hw civilizd pp...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>impct of coronavirus i hve sen hw civilizd ppl...</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18913</th>\n",
       "      <td>#CroozefmNews \\r\\r\\nPresident Museveni has ord...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>croozefmnews president museveni has ordered th...</td>\n",
       "      <td>35</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30206</th>\n",
       "      <td>#LDA City Lahore Residential Files Prices Upda...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>lda city lahore residential files prices updat...</td>\n",
       "      <td>43</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26678</th>\n",
       "      <td>Eine wahre #CoronaGeschichte:\\r\\r\\n\\r\\r\\nWenn ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>eine wahre coronageschichte wenn dir an der su...</td>\n",
       "      <td>29</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12389</th>\n",
       "      <td>Okay, so I just checked the drug prices for #P...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>okay so i just checked the drug prices for pla...</td>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>I work at a grocery store.\\r\\r\\nWe wont get an...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i work at a grocery store we wont get any toil...</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>?Bitte anschauen! (1/2)\\r\\r\\n\\r\\r\\nEmotionaler...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>bitte anschauen 12 emotionaler aufruf von geha...</td>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>hiked prices in the face of the Covid-19 crise...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>hiked prices in the face of the covid19 crises...</td>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36305</th>\n",
       "      <td>Sterile disposable anti bacterial wet wipes an...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>sterile disposable anti bacterial wet wipes an...</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36306</th>\n",
       "      <td>For sell Sterile disposable anti bacterial wet...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>for sell sterile disposable anti bacterial wet...</td>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>Hi @Zomato I felt hungry loggd in ur app tryd ...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>hi i felt hungry loggd in ur app tryd to add 4...</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40778</th>\n",
       "      <td>#Covid_19 2days Stay-at-home activities\\r\\r\\nU...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>covid19 2days stayathome activities up 630am f...</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OriginalTweet           Sentiment  \\\n",
       "1638   ZÃ¡sah policie proti spekulant?m s rouÂkami. ...             Neutral   \n",
       "37156  11 Nisan Cumartesi itibariyle ?BBÂnin tÃ¼m hi...             Neutral   \n",
       "16632  Bir mÃ¼ddettir sÃ¼permarketlerin lojistik hizm...             Neutral   \n",
       "13691  Hoy aplaudo a mi segunda familia #AplaudoANues...             Neutral   \n",
       "27005  Supermercados Econo confirman que un empleado ...             Neutral   \n",
       "14593  Na, wer war denn da am Werk? Gestern Nachmitta...  Extremely Negative   \n",
       "28899  Kindly contact Us bamy global merchandise for ...            Positive   \n",
       "11213  Keine WertgegenstÃ¤nde im Fahrzeug lassen! - D...            Negative   \n",
       "4844   Impct of #coronavirus i hve sen hw civilizd pp...  Extremely Negative   \n",
       "18913  #CroozefmNews \\r\\r\\nPresident Museveni has ord...  Extremely Negative   \n",
       "30206  #LDA City Lahore Residential Files Prices Upda...             Neutral   \n",
       "26678  Eine wahre #CoronaGeschichte:\\r\\r\\n\\r\\r\\nWenn ...             Neutral   \n",
       "12389  Okay, so I just checked the drug prices for #P...            Positive   \n",
       "1697   I work at a grocery store.\\r\\r\\nWe wont get an...            Positive   \n",
       "8730   ?Bitte anschauen! (1/2)\\r\\r\\n\\r\\r\\nEmotionaler...            Negative   \n",
       "14582  hiked prices in the face of the Covid-19 crise...            Negative   \n",
       "36305  Sterile disposable anti bacterial wet wipes an...            Negative   \n",
       "36306  For sell Sterile disposable anti bacterial wet...            Negative   \n",
       "9238   Hi @Zomato I felt hungry loggd in ur app tryd ...  Extremely Positive   \n",
       "40778  #Covid_19 2days Stay-at-home activities\\r\\r\\nU...             Neutral   \n",
       "\n",
       "                                              text_clean  text_len  token_lens  \n",
       "1638   zsah policie proti spekulantm s roukami na mj ...        39         100  \n",
       "37156  11 nisan cumartesi itibariyle bbnin tm hizmetl...        39          98  \n",
       "16632  bir mddettir spermarketlerin lojistik hizmeti ...        36          92  \n",
       "13691  hoy aplaudo a mi segunda familia aplaudoanuest...        38          84  \n",
       "27005  supermercados econo confirman que un empleado ...        39          80  \n",
       "14593  na wer war denn da am werk gestern nachmittag ...        37          80  \n",
       "28899  kindly contact us bamy global merchandise for ...        37          80  \n",
       "11213  keine wertgegenstnde im fahrzeug lassen diesen...        33          79  \n",
       "4844   impct of coronavirus i hve sen hw civilizd ppl...        48          79  \n",
       "18913  croozefmnews president museveni has ordered th...        35          79  \n",
       "30206  lda city lahore residential files prices updat...        43          78  \n",
       "26678  eine wahre coronageschichte wenn dir an der su...        29          78  \n",
       "12389  okay so i just checked the drug prices for pla...        35          77  \n",
       "1697   i work at a grocery store we wont get any toil...        37          77  \n",
       "8730   bitte anschauen 12 emotionaler aufruf von geha...        36          77  \n",
       "14582  hiked prices in the face of the covid19 crises...        47          77  \n",
       "36305  sterile disposable anti bacterial wet wipes an...        31          76  \n",
       "36306  for sell sterile disposable anti bacterial wet...        32          75  \n",
       "9238   hi i felt hungry loggd in ur app tryd to add 4...        55          75  \n",
       "40778  covid19 2days stayathome activities up 630am f...        37          75  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='token_lens', ascending=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>token_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12389</th>\n",
       "      <td>Okay, so I just checked the drug prices for #P...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>okay so i just checked the drug prices for pla...</td>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>I work at a grocery store.\\r\\r\\nWe wont get an...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i work at a grocery store we wont get any toil...</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>?Bitte anschauen! (1/2)\\r\\r\\n\\r\\r\\nEmotionaler...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>bitte anschauen 12 emotionaler aufruf von geha...</td>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>hiked prices in the face of the Covid-19 crise...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>hiked prices in the face of the covid19 crises...</td>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36305</th>\n",
       "      <td>Sterile disposable anti bacterial wet wipes an...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>sterile disposable anti bacterial wet wipes an...</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OriginalTweet Sentiment  \\\n",
       "12389  Okay, so I just checked the drug prices for #P...  Positive   \n",
       "1697   I work at a grocery store.\\r\\r\\nWe wont get an...  Positive   \n",
       "8730   ?Bitte anschauen! (1/2)\\r\\r\\n\\r\\r\\nEmotionaler...  Negative   \n",
       "14582  hiked prices in the face of the Covid-19 crise...  Negative   \n",
       "36305  Sterile disposable anti bacterial wet wipes an...  Negative   \n",
       "\n",
       "                                              text_clean  text_len  token_lens  \n",
       "12389  okay so i just checked the drug prices for pla...        35          77  \n",
       "1697   i work at a grocery store we wont get any toil...        37          77  \n",
       "8730   bitte anschauen 12 emotionaler aufruf von geha...        36          77  \n",
       "14582  hiked prices in the face of the covid19 crises...        47          77  \n",
       "36305  sterile disposable anti bacterial wet wipes an...        31          76  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[12:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens_test = []\n",
    "\n",
    "for txt in df_test['text_clean'].values:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens_test.append(len(tokens))\n",
    "    \n",
    "max_len=np.max(token_lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX TOKENIZED SENTENCE LENGTH: 96\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 286, TEXT: so hard to decide as much as i want to hodl my 2 ccdcv4 token our place is declared to lock down due to covid19 i will use this to buy some food to stock txnid093bd1db0c0d3a62af15883138a5f57d4cef35ae14e31e602b74489dd2524c7f my b\n",
      "INDEX: 345, TEXT: informoval jsem zstupce vech obchodnch etzc o aktulnch opatench vldy etzce jsou zsobovny na 95 take nen dvod panikait zsoby potravin fakt nedojdou nen opravdu dvod dnes obsadit a vykoupit supermarkety\n",
      "INDEX: 2380, TEXT: ahora seguid llorando por el papel higinico que no he comprado porque an tengo seguid creando histeria y preocupacin poniendo fotos de gente en pnico y estanteras vacas que yo seguir yendo a comercios responsables de barrio donde nos cuidan hoy y siempre gracias\n"
     ]
    }
   ],
   "source": [
    "token_lens_test = []\n",
    "\n",
    "for i,txt in enumerate(df_test['text_clean'].values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens_test.append(len(tokens))\n",
    "    if len(tokens)>80:\n",
    "        print(f\"INDEX: {i}, TEXT: {txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['token_lens'] = token_lens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>token_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>@Rhett800cc So hard to decide??. As much as I ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>so hard to decide as much as i want to hodl my...</td>\n",
       "      <td>38</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>Ahora seguid llorando por el papel higiénico (...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>ahora seguid llorando por el papel higinico qu...</td>\n",
       "      <td>44</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Informoval jsem zástupce vech obchodních ?et?...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>informoval jsem zstupce vech obchodnch etzc o ...</td>\n",
       "      <td>31</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>DTF-Dont Touch Face\\r\\r\\nDWBH-Do Wash Both Ha...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>dtfdont touch face dwbhdo wash both hands gtfo...</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Im in the DC/Maryland/Virginia (DMV) area &amp;am...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im in the dcmarylandvirginia dmv area amphave ...</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>Stop misusing ur privilege amp grow up Some1 c...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>stop misusing ur privilege amp grow up some1 c...</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>For those that are cashlong, patient,calm&amp;amp;...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>for those that are cashlong patientcalmamphave...</td>\n",
       "      <td>44</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Lidl is total chaos, queues as long as the ais...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>lidl is total chaos queues as long as the aisl...</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>COVID-19: Your government will save ITSELF not...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>covid19 your government will save itself not y...</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Stop #frenzybuying. You don't need most of wha...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>stop frenzybuying you dont need most of what y...</td>\n",
       "      <td>38</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment  \\\n",
       "286   @Rhett800cc So hard to decide??. As much as I ...            Negative   \n",
       "2383  Ahora seguid llorando por el papel higiénico (...            Negative   \n",
       "345   Informoval jsem zástupce vech obchodních ?et?...             Neutral   \n",
       "1485  DTF-Dont Touch Face\\r\\r\\nDWBH-Do Wash Both Ha...  Extremely Negative   \n",
       "1209  Im in the DC/Maryland/Virginia (DMV) area &am...            Positive   \n",
       "3505  Stop misusing ur privilege amp grow up Some1 c...            Positive   \n",
       "1789  For those that are cashlong, patient,calm&amp;...  Extremely Positive   \n",
       "855   Lidl is total chaos, queues as long as the ais...  Extremely Negative   \n",
       "2740  COVID-19: Your government will save ITSELF not...            Positive   \n",
       "2997  Stop #frenzybuying. You don't need most of wha...  Extremely Negative   \n",
       "\n",
       "                                             text_clean  text_len  token_lens  \n",
       "286   so hard to decide as much as i want to hodl my...        38          96  \n",
       "2383  ahora seguid llorando por el papel higinico qu...        44          94  \n",
       "345   informoval jsem zstupce vech obchodnch etzc o ...        31          86  \n",
       "1485  dtfdont touch face dwbhdo wash both hands gtfo...        42          77  \n",
       "1209  im in the dcmarylandvirginia dmv area amphave ...        45          74  \n",
       "3505  stop misusing ur privilege amp grow up some1 c...        57          73  \n",
       "1789  for those that are cashlong patientcalmamphave...        44          71  \n",
       "855   lidl is total chaos queues as long as the aisl...        62          70  \n",
       "2740  covid19 your government will save itself not y...        43          70  \n",
       "2997  stop frenzybuying you dont need most of what y...        38          70  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.sort_values(by='token_lens', ascending=False)\n",
    "df_test.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>token_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>Stop misusing ur privilege amp grow up Some1 c...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>stop misusing ur privilege amp grow up some1 c...</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>For those that are cashlong, patient,calm&amp;amp;...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>for those that are cashlong patientcalmamphave...</td>\n",
       "      <td>44</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Lidl is total chaos, queues as long as the ais...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>lidl is total chaos queues as long as the aisl...</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment  \\\n",
       "3505  Stop misusing ur privilege amp grow up Some1 c...            Positive   \n",
       "1789  For those that are cashlong, patient,calm&amp;...  Extremely Positive   \n",
       "855   Lidl is total chaos, queues as long as the ais...  Extremely Negative   \n",
       "\n",
       "                                             text_clean  text_len  token_lens  \n",
       "3505  stop misusing ur privilege amp grow up some1 c...        57          73  \n",
       "1789  for those that are cashlong patientcalmamphave...        44          71  \n",
       "855   lidl is total chaos queues as long as the aisl...        62          70  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.iloc[5:]\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11381\n",
       "Negative               9889\n",
       "Neutral                7560\n",
       "Extremely Positive     6618\n",
       "Extremely Negative     5475\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sentiment'] = df_test['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    17999\n",
       "0    15364\n",
       "1     7560\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Balancing by RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "train_x, train_y = ros.fit_resample(np.array(df['text_clean']).reshape(-1, 1), np.array(df['Sentiment']).reshape(-1, 1));\n",
    "train_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text_clean', 'Sentiment']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17999\n",
       "2    17999\n",
       "1    17999\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_os['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Validation - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_os['text_clean'].values\n",
    "y = train_os['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['text_clean'].values\n",
    "y_test = df_test['Sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_le = y_train.copy()\n",
    "y_valid_le = y_valid.copy()\n",
    "y_test_le = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = preprocessing.OneHotEncoder()\n",
    "y_train = ohe.fit_transform(np.array(y_train).reshape(-1, 1)).toarray()\n",
    "y_valid = ohe.fit_transform(np.array(y_valid).reshape(-1, 1)).toarray()\n",
    "y_test = ohe.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: 48597\n",
      "VALIDATION DATA: 5400\n",
      "TESTING DATA: 3787\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAINING DATA: {X_train.shape[0]}\\nVALIDATION DATA: {X_valid.shape[0]}\\nTESTING DATA: {X_test.shape[0]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CountVectorizer()\n",
    "X_train_cv =  clf.fit_transform(X_train)\n",
    "X_test_cv = clf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
    "X_train_tf = tf_transformer.transform(X_train_cv)\n",
    "X_test_tf = tf_transformer.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.fit(X_train_tf, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred = nb_clf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data,max_len=MAX_LEN) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(data)):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            data[i],\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = tokenize(X_train, MAX_LEN)\n",
    "val_input_ids, val_attention_masks = tokenize(X_valid, MAX_LEN)\n",
    "test_input_ids, test_attention_masks = tokenize(X_test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_tf_utils.py:2919\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2917\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[0;32m   2922\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m--> 223\u001b[0m         original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_tf_utils.py:1134\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1133\u001b[0m     call_context \u001b[38;5;241m=\u001b[39m get_call_context_function()\n\u001b[1;32m-> 1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mcall_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39min_call:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_model, max_len=MAX_LEN):\n",
    "    \n",
    "    ##params###\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "\n",
    "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
    "    \n",
    "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
    "    \n",
    "    embeddings = bert_model([input_ids,attention_masks])[1]\n",
    "    \n",
    "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(embeddings)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
    "    \n",
    "    model.compile(opt, loss=loss, metrics=accuracy)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[64], line 13\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(bert_model, max_len)\u001b[0m\n\u001b[0;32m      9\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(max_len,),dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(max_len,),dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)(embeddings)\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs \u001b[38;5;241m=\u001b[39m [input_ids,attention_masks], outputs \u001b[38;5;241m=\u001b[39m output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_utils.py:4339\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4340\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4344\u001b[0m     )\n\u001b[0;32m   4346\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4347\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "model = create_model(bert_model, MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bert = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=4, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bert = model.predict([test_input_ids,test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bert =  np.zeros_like(result_bert)\n",
    "y_pred_bert[np.arange(len(y_pred_bert)), result_bert.argmax(1)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5412f0614946ad8806e90853063f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858ec376ac964d35a378987efdf52192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79efd8731c0244b1a56551f9a9745221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793fc1c13d7e4f5f9fe1cb6d8f2585e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbc712501604e50b7d3f89d65b12321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_roberta = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in X_train:\n",
    "    tokens = tokenizer_roberta.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "max_length=np.max(token_lens)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_roberta(data,max_len=MAX_LEN) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(data)):\n",
    "        encoded = tokenizer_roberta.encode_plus(\n",
    "            data[i],\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = tokenize_roberta(X_train, MAX_LEN)\n",
    "val_input_ids, val_attention_masks = tokenize_roberta(X_valid, MAX_LEN)\n",
    "test_input_ids, test_attention_masks = tokenize_roberta(X_test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_model, max_len=MAX_LEN):\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
    "    output = bert_model([input_ids,attention_masks])\n",
    "    output = output[1]\n",
    "    output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(output)\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "    model.compile(opt, loss=loss, metrics=accuracy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd1d40e31c54739b5dad9abeb4e25f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m roberta_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFRobertaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroberta-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_tf_utils.py:2919\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2917\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[0;32m   2922\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m--> 223\u001b[0m         original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\modeling_tf_utils.py:1134\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1133\u001b[0m     call_context \u001b[38;5;241m=\u001b[39m get_call_context_function()\n\u001b[1;32m-> 1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mcall_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39min_call:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "roberta_model = TFRobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(roberta_model, MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=4, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_roberta = model.predict([test_input_ids,test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_roberta =  np.zeros_like(result_roberta)\n",
    "y_pred_roberta[np.arange(len(y_pred_roberta)), result_roberta.argmax(1)] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
